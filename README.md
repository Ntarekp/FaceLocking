# FaceLocking

A **Face Locking and Action Detection system** built on top of a research-grade face recognition pipeline.
This project adds **target locking**, **stable tracking**, and **facial action detection** (blink, smile, move) to the core recognition engine.

---

## âœ¨ Features

* ğŸ“· Real-time webcam capture
* ğŸ§  Face detection
* ğŸ¯ 5-point facial landmark extraction
* ğŸ§­ Face alignment (112Ã—112 ArcFace standard)
* ğŸ§¬ ArcFace embeddings via ONNX Runtime
* ğŸ“¦ Face enrollment & database creation
* ğŸ” Live face recognition with threshold control
* ğŸ§ª Evaluation of genuine vs impostor distances

---

## ğŸ“ Project Structure

```
face-recognition-5pt/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ enroll/          # Raw & aligned enrollment images
â”‚   â””â”€â”€ db/              # Face embeddings database
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ embedder_arcface.onnx
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ init_projects.py # Project generator
â”‚   â”œâ”€â”€ camera.py        # Webcam test
â”‚   â”œâ”€â”€ detect.py        # Face detection
â”‚   â”œâ”€â”€ landmarks.py     # 5-point landmark extraction
â”‚   â”œâ”€â”€ align.py         # Face alignment
â”‚   â”œâ”€â”€ embed.py         # ArcFace embedding
â”‚   â”œâ”€â”€ enroll.py        # Enrollment pipeline
â”‚   â”œâ”€â”€ recognize.py     # Live recognition
â”‚   â”œâ”€â”€ evaluate.py      # Threshold evaluation
â”‚   â””â”€â”€ haar_5pt.py      # Haar + landmark helpers
â”‚
â””â”€â”€ book/                # Reference materials
```

---

## âš™ï¸ Requirements

* Python **3.9+** (recommended)
* Webcam
* OS: Windows / Linux / macOS

### Python Dependencies

```
opencv-python
numpy
onnxruntime
scipy
tqdm
mediapipe
```

Install all dependencies:

```bash
pip install opencv-python numpy onnxruntime scipy tqdm mediapipe
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Create Project Structure

```bash
python src/init_projects.py
```

---

### 2ï¸âƒ£ Test Webcam

```bash
python -m src.camera
```

Press **q** to exit.

---

### 3ï¸âƒ£ Face Detection

```bash
python -m src.detect
```

You should see a bounding box around detected faces.

---

### 4ï¸âƒ£ Landmark Detection (5-point)

```bash
python -m src.landmarks
```

Five facial landmarks should appear:

* Left eye
* Right eye
* Nose
* Left mouth corner
* Right mouth corner

---

### 5ï¸âƒ£ Face Alignment (Critical Step)

```bash
python -m src.align
```

Outputs a **112Ã—112 aligned face** suitable for ArcFace.

---

## y ArcFace Model Setup

Download the **ArcFace ONNX model** (InsightFace):

```bash
curl -L -o buffalo_l.zip https://sourceforge.net/projects/insightface.mirror/files/v0.7/buffalo_l.zip/download
unzip buffalo_l.zip
cp w600k_r50.onnx models/embedder_arcface.onnx
```

(Optional cleanup)

```bash
rm buffalo_l.zip w600k_r50.onnx
```

---

### Validate Embeddings

```bash
python -m src.embed
```

Expected output:

* Embedding dimension: **512**
* High cosine similarity between same-face frames

---

## ğŸ‘¤ Enrollment

Register known identities into the database.

```bash
python -m src.enroll
```

Controls:

* **SPACE** â†’ capture frame
* **A** â†’ auto capture
* **Q** â†’ quit and save

Enrollment data saved in:

```
data/enroll/
data/db/
```

---

##  Threshold Evaluation

Determine the optimal recognition threshold:

```bash
python -m src.evaluate
```

Outputs:

* Genuine distances
* Impostor distances
* Recommended threshold value

---

##  Live Recognition

```bash
python -m src.recognize
```

Controls:

* **+** increase threshold (more permissive)
* **-** decrease threshold (stricter)
* **Q** quit

---

##  System Pipeline

### Enrollment

```
Camera â†’ Detect â†’ Landmarks â†’ Align â†’ Embed â†’ Average â†’ Save
```

### Recognition

```
Camera â†’ Detect â†’ Landmarks â†’ Align â†’ Embed â†’ Compare â†’ Threshold â†’ Result
```

---

##  Common Pitfalls

* Skipping face alignment
* Enrolling with poor lighting
* Using only one enrollment image
* Changing models without re-enrolling

---

##  Notes

* CPU-only (no GPU required)
* Deterministic and explainable pipeline
* Suitable for attendance systems, access control, exams, and research

---

##  License

This project is provided for **educational and research purposes**.

---

## ğŸ™Œ Acknowledgements

* InsightFace / ArcFace
* OpenCV
* MediaPipe

---

---

## ğŸ”’ Face Locking Feature

This system supports **Face Locking** for behavior tracking:

### How Face Locking Works

1. **Manual Face Selection**: At startup, select one enrolled identity to lock (e.g., "Gabi" or "Fani").
2. **Locking**: When the selected face appears and is confidently recognized, the system locks onto it and displays a clear visual indicator (blue bounding box and text overlay).
3. **Stable Tracking**: The system tracks the locked face across frames, tolerates brief recognition failures, and only releases the lock if the face disappears for a set duration (~2 seconds).
4. **Action Detection**: While locked, the system detects and records simple face actions:
	 - Face moved left
	 - Face moved right
	 - Eye blink
	 - Smile or laugh (simple detection)
5. **Action History Recording**: All detected actions are recorded to a timeline file.

### Actions Detected

- **move_left**: Face moved left in the frame
- **move_right**: Face moved right in the frame
- **eye_blink**: Eye blink detected
- **smile**: Smile or laugh detected

### History File Naming and Storage

- History files are named as `<face>_history_<timestamp>.txt` (e.g., `gabi_history_20260129112099.txt`).
- Each record includes:
	- Timestamp
	- Action type
	- Brief description or value
- Files are stored in `data/db/`.

---

## ğŸ“– Example History Record

```
2026-02-01 11:20:59	move_left	Face moved left by 32.0 px
2026-02-01 11:21:01	eye_blink	Left eye blink detected
2026-02-01 11:21:03	smile	Smile/laugh detected
```

---

Happy hacking ğŸš€
